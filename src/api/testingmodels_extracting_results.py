# -*- coding: utf-8 -*-
"""TestingModels_extracting_results.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bz4Ne7kjWwXJZmGQ2e2th_vwKaFKqGo6

# Library imports
"""



# Miscelanious Modules
import tensorflow as tf
import os
import sys
import inspect
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib
import keras as K
import sklearn as sk
import pickle
import shutil
import cv2
import json

# Objects and methods
# get_ipython().run_line_magic('matplotlib', 'inline')
from PIL import Image, ImageOps, ImageEnhance, ImageFile
from numpy import random
from IPython.display import SVG
from distutils.version import LooseVersion as LV
from sklearn.model_selection import train_test_split
from shutil import copyfile
from datetime import datetime
from tensorflow.python.framework import ops
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report, roc_curve, roc_auc_score, balanced_accuracy_score
from sklearn.utils.class_weight import compute_class_weight

# Keras objects and methods
from keras.models import Sequential,model_from_json, load_model
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D,Conv2D
from keras import backend as K
from keras import callbacks
from keras import __version__

import numpy as np
import tensorflow as tf
np.random.seed(42)
tf.random.set_seed(42)

#TensorFlow Version
print(tf.__version__)
print(tf.config.list_physical_devices('GPU'))


#Python Version using
from platform import python_version
print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())

"""# Path definitions"""

# from google.colab import drive
# drive.mount('/content/drive')



#!unzip /content/drive/MyDrive/Imagens128.zip -d dataset/

# Path to directories with dry and wet images division
base_dir1 = '../../imgs'
base_dir2 = '../../imgs'

# train, validation and test sub-directories
train_dir = os.path.join(base_dir1, 'train')
validation_dir = os.path.join(base_dir1, 'validation')
test_dir = os.path.join(base_dir1, 'test')
#test_dir = os.path.join(base_dir2, 'test_holdout128')
print(base_dir1)

exit(1)

"""# Filtering Definition"""

def suavizar(image):
    suavizada = cv2.GaussianBlur(image, (5, 5), 0)
    return suavizada

# train_datagen = ImageDataGenerator(
#    preprocessing_function=suavizar, shear_range=0.2,zoom_range=0.2, horizontal_flip=True, rescale=1./255
# )

#Pixel normalization for test data
test_datagen = ImageDataGenerator(rescale=1./255)


#Pixel normalization for validation data
validation_datagen = ImageDataGenerator(rescale=1./255)

image_size=128

# batch_size=2000


# Applying filter accross train directory with batch size = 6:
#train_generator = train_datagen.flow_from_directory(
#      train_dir,
#      target_size=(image_size,image_size), # size image
#      batch_size = batch_size, shuffle = True, class_mode='binary', classes=['dry', 'wet']
#)


# Applying filter accross train directory with batch size = 6:
# validation_generator = validation_datagen.flow_from_directory(
#      validation_dir,
#      target_size=(image_size,image_size), batch_size = 6, class_mode='binary', classes=['dry', 'wet'],
#)

# Applying filter accross test directory with batch size =1:
test_generator = test_datagen.flow_from_directory(
    test_dir,
      target_size=(image_size,image_size), batch_size = 1,  class_mode='binary', shuffle=False
)
#bbbb

# Assuming you have already created train_generator using train_datagen.flow_from_directory()

# Get the class indices (mapping of class names to their corresponding index)
class_indices = test_generator.class_indices

# Get the class labels (indices) for each image
class_labels = test_generator.classes

# Count the number of occurrences of each class label
unique, counts = np.unique(class_labels, return_counts=True)

# Create a dictionary mapping class names to their respective counts
class_counts = {class_name: counts[idx] for class_name, idx in class_indices.items()}

print("Number of images per class:")
for class_name, count in class_counts.items():
    if class_name == 'dry':
      dry_count = count
    else:
      wet_count = count

    print(f"{class_name}: {count}")

print(dry_count)
print(wet_count)

"""# Layers Of Model"""

model = Sequential()

# Primeira parte com convoluções e maxpooling = CAMADA 1 - LAYER 0
model.add(Conv2D(32,(3,3), input_shape=(128,128,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Segunda parte com convoluções e maxpooling = CAMADA 2 - LAYER 1
model.add(Conv2D(32,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


#Terceira parte com convoluções e maxpooling= CAMADA 3 - LAYER 2
model.add(Conv2D(32, (3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(units = 128, activation = 'relu')) # altere os neuronios
model.add(Dense(units = 128, activation = 'relu')) # altere os neuronios
model.add(Dense(units = 1, activation = 'sigmoid'))

import tensorflow as tf
optimizer = Adam(learning_rate=0.004)
model.compile(loss='binary_crossentropy', metrics=['accuracy'])

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        # Restrict TensorFlow to only use the first GPU
        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(f'Physical GPUs: {gpus}, Logical GPUs: {logical_gpus}')
    except RuntimeError as e:
        print(e)
else:
    print('Nenhuma GPU detectada.')

"""# Train Model"""

with tf.device('/device:GPU:0'):
    history_list = []
    accuracy_list = []
    loss_list = []
    val_accuracy_list = []
    val_loss_list = []

    check_point_flag_val_loss = tf.keras.callbacks.ModelCheckpoint(
        '/content/bests/Models/h5/Model15_val_loss.h5',
        monitor='val_loss', save_best_only = False,
        mode = 'min', patience = 100
        )

    Early_stopping = callbacks.EarlyStopping(
        monitor='val_loss', patience=100
        )


    history = model.fit(
        train_generator,
        epochs = 1000,
        validation_data=validation_generator,
        callbacks = [check_point_flag_val_loss, Early_stopping]
    )

    accuracy_list.append(history.history['accuracy'])
    loss_list.append(history.history['loss'])
    val_accuracy_list.append(history.history['val_accuracy'])
    val_loss_list.append(history.history['val_loss'])

def transfer_model_to_json():
    checkpoint_path_json = '/content/bests/Models/h5/model15.json'
    model_to_json = model.to_json()

    with open(checkpoint_path_json, 'w') as my_jsonmodel:
        my_jsonmodel.write(model_to_json)
    print("modelo foi salvo como json")

    my_jsonmodel.close()


transfer_model_to_json()
# model.save('drive/MyDrive/Models/h5/model.weights13.h5')
# model.save_weights('drive/MyDrive/Models/h5/model.weights13.h5')

'''if __name__ == "__main__":
    if not pyuac.isUserAdmin():
        print("Re-launching as admin!")
        pyuac.runAsAdmin(transfer_model_to_json())
        pyuac.runAsAdmin(model.save('../models\h5\model.weights8.h5'))
        pyuac.runAsAdmin(model.save_weights('..\models\h5\model.weights8.h5'))
    else:
        main(transfer_model_to_json())
        main(model.save('..\models\h5\model.weights8.h5'))
        main(model.save_weights('..\models\h5\model.weights8.h5'))

'''

"""# Loading Models

## Função para lidar com imagens corrompidas
"""

def iterator_scanner(img):
    c=0
    while c<195:

        try:
            data, labels = next(img)
            yield data, labels

        except:
            pass
        c+=1

#aa
"""## Reading weights and json model files"""

json_file = open('/content/drive/MyDrive/Models/json/M2.json','r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)

loaded_model.load_weights('/content/drive/MyDrive/Models/h5/M1_weights_epoch_90.h5')
print('Loaded model from disk')

loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

score = loaded_model.evaluate(test_generator)


print("{}: {}".format(loaded_model.metrics_names[1],score[1]*100))
print("{}: {}".format(loaded_model.metrics_names[0],score[0]*100))

loaded_model.summary()

predictions = loaded_model.predict(test_generator)

#aaa

"""# Visualizando resultado do treinamento

## Ajustando trashold e criando vizualizações
"""

#threshold=0.50392
threshold=0.877976

#threshold=0.497
prediction_percent=(predictions*100).round(8)
predicted_labels = (predictions > threshold).astype(int) # Converter as previsões em rótulos (classes)
true_labels = test_generator.classes# Obter os rótulos verdadeiros do conjunto de teste
true_labels = true_labels[:-1]
class_names = list(test_generator.class_indices.keys())
print(class_names)

print(true_labels)
#print(prediction_percent)


print(sorted(prediction_percent)[:3])
print(sorted(prediction_percent)[-3:])
print(prediction_percent.mean())
np.median(prediction_percent)


for i in sorted(prediction_percent):
  print(i)

# Calcule a matriz de confusão
confusion = confusion_matrix(true_labels, predicted_labels[:-1])

# Normalize a matriz de confusão para ter valores entre 0 e 1
confusion = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]

# Crie o heatmap da matriz de confusão
plt.figure(figsize=(4, 3))
sns.heatmap(confusion, annot=True, fmt=".2f", cmap="Blues", cbar=False)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.xticks(np.arange(len(class_names)) + 0.5, class_names)
plt.yticks(np.arange(len(class_names)) + 0.5, class_names)
plt.show()

roc_auc = roc_auc_score(true_labels, predicted_labels[:-1])
auc_wb = balanced_accuracy_score(true_labels, predicted_labels[:-1])
print(f'ROC-AUC: {roc_auc:.5f}')
print(f'ROC-AUC: {auc_wb:.5f}')

class_report = classification_report(true_labels, predicted_labels[:-1])
print("Classification Report:\n", class_report)

print(wet_count)
print(dry_count)

# curva ROC
fpr, tpr, thresholds = roc_curve(true_labels, predicted_labels[:-1])
roc_auc = roc_auc_score(true_labels, predicted_labels[:-1]) #ROC-AUC

# ROC-AUC balanced:
class_w = compute_class_weight('balanced', classes=np.unique(true_labels), y = true_labels)
weighted_auc = roc_auc_score(true_labels, predicted_labels[:-1], sample_weight=class_w[true_labels])

print(f'ROC-AUC: {roc_auc:.5f}')
print(f'ROC-AUCwb: {weighted_auc:.5f}')

plt.figure(figsize=(4, 3))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC-AUC = {roc_auc:.11f}')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve')
plt.legend(loc='lower right')
plt.show()

fig, axes = plt.subplots(3, 5, figsize=(12, 6))
axes = axes.ravel()
predicted_classes = np.argmax(predictions, axis=1)
class_labels = list(test_generator.class_indices.keys())
file_names = test_generator.filenames[:]

for i in range(10):
    index = random.randint(0, 200) + i  # Starting from position
    axes[i].imshow(test_generator[index][0][0])
    predicted_label = class_labels[predicted_classes[index]]
    true_label = class_labels[true_labels[index]]
    confidence = predictions[index][predicted_classes[index]] * 100
    if confidence < (threshold*100):
        axes[i].set_title("Predicted: {} \nConfidence: ({:.2f}%) \nTrue: {}\nlabel: {}".format("dry", confidence, true_label, file_names[index][4:]), fontsize=8)
        axes[i].axis('off')



    else:
        axes[i].set_title("Predicted: {} \nConfidence: ({:.2f}%) \nTrue: {}\nlabel: {} ".format("wet", confidence, true_label, file_names[index][4:]), fontsize=8)
        axes[i].axis('off')

plt.tight_layout()
plt.show()

print("Valor mínimo:", min(prediction_percent))
print("Threshold*100:", threshold * 100)
print("Valor máximo:", max(prediction_percent))

# Criar o boxplot
fig, ax = plt.subplots()
sns.boxplot(prediction_percent, ax=ax)

# Obter os valores dos outliers
outliers = []
for line in ax.lines:
    if line.get_linestyle() == '':
        outliers.extend(line.get_ydata())

if outliers:
    print("Outliers:", np.array(outliers))
else:
    print("Nenhum outlier encontrado")

# Mostrar o gráfico
plt.title('Boxplot dos Dados')
plt.xlabel('Categoria')
plt.ylabel('Valores')
plt.show()

"""## Plotando curvas de treinamento"""

filters = loaded_model.layers[0].get_weights()[0]

from skimage.color import rgb2gray
filters = loaded_model.weights[0].numpy()
filters_norm= (filters - np.min(filters)) / (np.max(filters) - np.min(filters))
fig, axes = plt.subplots(4, 4, figsize=(6, 6))
for i, ax in enumerate(axes.flatten()):
  ax.imshow(np.squeeze(filters_norm[:, :, :, i]), cmap='gray')
  ax.set_yticks([])
  ax.set_xticks([])

#feature

filters = loaded_model.layers[0].get_weights()[0]

filters_gray = np.mean(filters, axis=2)
fig.subplots_adjust(hspace=0.1, wspace=0.1)

filters_norm = (filters_gray - np.min(filters_gray)) / (np.max(filters_gray) - np.min(filters_gray))

fig, axes = plt.subplots(4, 4, figsize=(6, 6))
for i, ax in enumerate(axes.flatten()):
    ax.imshow(filters_norm[:, :, i], cmap='gray')
    ax.set_yticks([])
    ax.set_xticks([])

plt.show()

#features escala de cinza
inp = loaded_model.layers[0].input
outs = [layer.output for layer in loaded_model.layers]

layerized_model = tf.keras.models.Model(inp, outs)
Omat = layerized_model.predict(test_generator)

fig, axes = plt.subplots(4, 4, figsize=(4, 4))

for i, ax in enumerate(axes.flatten()):
  ax.imshow(np.squeeze(Omat[0][0, :, :, i]), cmap='gray')
  ax.set_yticks([])
  ax.set_xticks([])

fig, axes = plt.subplots(4, 4, figsize=(4, 4))

for i, ax in enumerate(axes.flatten()):
 ax.imshow(np.squeeze(Omat[1][0, :, :, i]), cmap='gray')
 ax.set_yticks([])
 ax.set_xticks([])

#plota em portugues
fig, axes = plt.subplots(6, 5, figsize=(8, 8))
axes = axes.ravel()

for i in range(30):
    axes[i].imshow(test_generator[i][0][0])
    predicted_label = class_labels[predicted_classes[i]]
    true_label = class_labels[true_labels[i]]
    confidence = predictions[i][predicted_classes[i]] * 100
    if confidence<50:
         axes[i].set_title("Predição: {} \nConfiance: ({:.2f}%)".format("wet", confidence), fontsize=8)
         axes[i].axis('off')
    else:
        axes[i].set_title("Predição: {} \nConfiance: ({:.2f}%)".format("dry", confidence), fontsize=8)
        axes[i].axis('off')
plt.tight_layout()
plt.show()

#plota em ingles
fig, axes = plt.subplots(6, 5, figsize=(8, 8))
axes = axes.ravel()

for i in range(30):
    axes[i].imshow(test_generator[i][0][0])
    predicted_label = class_labels[predicted_classes[i]]
    true_label = class_labels[true_labels[i]]
    confidence = predictions[i][predicted_classes[i]] * 100
    if confidence<50:
         axes[i].set_title("Predição: {} \nConfiance: ({:.2f}%)".format("wet", confidence), fontsize=8)
         axes[i].axis('off')
    else:
        axes[i].set_title("Predição: {} \nConfiance: ({:.2f}%)".format("dry", confidence), fontsize=8)
        axes[i].axis('off')
plt.tight_layout()
plt.show()

img_path = 'C:\\Users\\joaog\\Desktop\\ALL\\MoistClassifier\\MoistClassifier\\concrete_dataset\\test\\wet\\wet1796.jpg'
img = Image.open(img_path)

img_flipped = img.transpose(method=Image.FLIP_LEFT_RIGHT)
img_rotated = img.rotate(45)

width, height = img.size
new_width, new_height = int(width * 0.6), int(height * 0.4)

# Redimensionando com rescale
img_rescaled = img.resize((new_width, new_height))

# Cria uma figura com dois subplots
fig, axes = plt.subplots(nrows=2, ncols=2)

# Plota a imagem original no primeiro subplot
axes[0,0].imshow(np.asarray(img))
axes[0,0].set_title("Original", fontsize=8)

# Plota a imagem modificada pelo data augmentation no segundo subplot
axes[0,1].imshow(np.asarray(img_flipped))
axes[0,1].set_title("Flip", fontsize=8)

# Plota a imagem modificada pelo data augmentation no terceiro subplot
axes[1,0].imshow(np.asarray(img_rotated))
axes[1,0].set_title("Rotation", fontsize=8)

# Plota a imagem original no primeiro subplot
axes[1,1].imshow(np.asarray(img_rescaled))
axes[1,1].set_title("Rescale", fontsize=8)

plt.subplots_adjust(wspace=0.1, hspace=0.05)
# Remove as marcas de ticks dos subplots
for ax in axes.flat:
    ax.set_xticks([])
    ax.set_yticks([])

# Exibe a figura
plt.show()

path = 'C:\\Users\\joaog\\Desktop\\ALL\\MoistClassifier\\MoistClassifier\\concrete_dataset\\test\\wet'
fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(4, 3))
ax = ax.flatten()
for i, img in enumerate(os.listdir(path)[:4]):
  img_path = os.path.join(path, img)
  if os.path.isfile(img_path):
    image = Image.open(img_path)
    image.thumbnail((100, 100))
    ax[i].imshow(image)
plt.tight_layout()
plt.show()

path = 'C:\\Users\\joaog\\Desktop\\ALL\\MoistClassifier\\MoistClassifier\\concrete_dataset\\test\\dry'
fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(4, 3))
ax = ax.flatten()
for i, img in enumerate(os.listdir(path)[:4]):
  img_path = os.path.join(path, img)
  if os.path.isfile(img_path):
    image = Image.open(img_path)
    image.thumbnail((100, 100))
    ax[i].imshow(image)
plt.tight_layout()
plt.show()

from PIL import Image, ImageEnhance


img_path = 'C:\\Users\\joaog\\Desktop\\ALL\\MoistClassifier\\MoistClassifier\\concrete_dataset\\test\\wet\\wet1796.jpg'
img = Image.open(img_path)

img_flipped = img.transpose(method=Image.FLIP_LEFT_RIGHT)
img_rotated = img.rotate(45)

width, height = img.size
new_width, new_height = int(width * 0.6), int(height * 0.4)

# Redimensionando com rescale
img_rescaled = img.resize((new_width, new_height))


enhanced_flipped = ImageEnhance.Sharpness(img_flipped)
enhanced_rotated = ImageEnhance.Sharpness(img_flipped)
enhanced_rescaled = ImageEnhance.Sharpness(img_rescaled)
enhanced_img = ImageEnhance.Sharpness(img)


sharpness_factor = 4.0

# Cria uma figura com dois subplots
fig, axes = plt.subplots(nrows=2, ncols=2)

# Plota a imagem original no primeiro subplot
axes[0,0].imshow(np.asarray(enhanced_img.enhance(sharpness_factor)))
axes[0,0].set_title("Original", fontsize=8)

# Plota a imagem modificada pelo data augmentation no segundo subplot
axes[0,1].imshow(np.asarray(enhanced_flipped.enhance(sharpness_factor)))
axes[0,1].set_title("Flip", fontsize=8)

# Plota a imagem modificada pelo data augmentation no terceiro subplot
axes[1,0].imshow(np.asarray(enhanced_rotated.enhance(sharpness_factor)))
axes[1,0].set_title("Rotation", fontsize=8)

# Plota a imagem original no primeiro subplot
axes[1,1].imshow(np.asarray(enhanced_rescaled.enhance(sharpness_factor)))
axes[1,1].set_title("Rescale", fontsize=8)

plt.subplots_adjust(wspace=0.1, hspace=0.05)
# Remove as marcas de ticks dos subplots
for ax in axes.flat:
    ax.set_xticks([])
    ax.set_yticks([])

# Exibe a figura
plt.show()

import gc
import torch
from torch import nn, optim, zeros
A = zeros(30000000000, dtype=torch.int8)
B = zeros(30000000000, dtype=torch.int8)
C = zeros(30000000000, dtype=torch.int8)
D = zeros(30000000000, dtype=torch.int8)
E = zeros(30000000000, dtype=torch.int8)
F = zeros(30000000000, dtype=torch.int8)
